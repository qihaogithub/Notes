原文：[https://zhuanlan.zhihu.com/p/671593883](https://zhuanlan.zhihu.com/p/671593883)


介绍了主界面和 comfyUI 相关的内容,下面主要介绍下 comfyUI 的常用节点和它们在工作流之中的主要功能。

| 采样器 | 负责在潜空间之中针对加噪和去噪来进行控制。 |
| ---- | ---- |
| 加载器 | 主要是加载各种不同功能的模型和工具的功能性节点。 |
| 调节器 | 针对工作流之中的部分内容信息进行调整 |
| 潜空间 | 主要负责在潜空间和现实空间之间的切换节点 |
| 图像控制 | 针对输出的现实空间图片进行调整控制 |
| 其他 | 其他类型功能 |

这里可以将comfyUI的节点分布大致分为上面提到的6种类型，以功能类型进行分类，下面会详细解释一下每一个的内容和对应sdwebUI相关的功能类型。

## **2.1 采样器**

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/20240220163757.png)


首先介绍的是采样器，目前的comfyUI采样器主要是分为普通的KSampler,和高级版KSampler（Advanced）。基础的采样器对比webUI的功能界面的内容大致相同。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-310cb2cc6dc33afe483f30cfc00cde98_b.jpg)

种子对应webUI的种子类型，常用的是处理种子的固定和随机性。步数和cfg也是相同的。其中差异化的是画面尺寸，在comfyUI之中需要作为图片编码的信息节点链接至latent_image之中。

另一个差异点就是批次和单位数量。webUI的单批次数量是8个，而comfyUI没有这个限制。取决于工作流之中产出的图片数量内容。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/20240220171358.png)

对于升级版本的KSamlper而言主要的区别在于增加了与种子，noise相关的参数设置。同时步数的范围也进行了更多的调整。

这部分更多的是用于SDXL的模型训练之中。

## **2.2 加载器**

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/20240220171606.png)

加载器这里是加载不同的模型，模型大致可以分为几个大类。分别是模型库相关，插件预训练模型相关，文字输入相关，放大器相关。

模型库这里的加载器最常用的就是ckpt和lora了。这里比较明显的是对标webUI之中选择不同模型的菜单界面。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-2a1e55ae6e65a5fd190441d7160f89bf_b.jpg)

其中ckpt模型是必须的，常驻作为左边第一个起始节点。中间的部分对于Lora等模型进行串联。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-81fc6e521c8f941bb69f1223cfdbc4a5_b.jpg)

这里以lora的workflow举例。需要从左边的model和clip进行接入，让ckpt在接入clip编码器时候进行一个内容变化。同时也可以在clip之中通过写入lora的词和权重进行添加。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/20240220171720.png)

然后controlnet加载器这部分比较特殊，相比lora的串联效果，controlnet的做法更加复杂是一个并联的内容。上图举一个controlnet canny的例子。

controlnet主要影响到的是正向的描述词，其中需要在其中添加一个调节器（后面会提到）。这个调节器的功能是将多个加载器并联的内容进行一个汇总。然后输入到采样器的正向描述之中。

这里最左边的就是常驻的ckpt节点，中间是3组并联内容，上面的是clip编码器正向部分。

中间的是controlnet的预训练模型加载器。对标controlnet无预处理器的设置。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-4e06b2ba0c047a6bcd78f112bf719053_b.jpg)

下面的是输入图像的加载器。对标webUI的这个环节。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-31cd06fae2dd0d03f06aea64049d9ded_b.jpg)

这里提前介绍这个调节器。分为简易和复杂

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-80a1689cbec2ba3c66b2cdc897ebe39a_b.jpg)

上图中的简易版本对应只有控制权重的滑块。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-87c244da3d8cea85f2c3e9e8d9ca8e78_b.jpg)

复杂的版本具有更加全的控制范围。可以做一些深度的操作（例如二维码隐藏图之类的效果）。

GlGENL，style Model和Clip Vison一类的偏向风格和插件相关的加载器这里具体工作流具体分析。再提到一个常用的就是Upscale模型。

这个对应的就是webUI的后期处理或者说是放大菜单。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-83dad1746aea8d2d7d3cee6992251c6a_b.jpg)

同样思路在使用加载了放大器进行输出入的时候也是需要并联这个加载器。同样需要一个Upscale image的调节器来将本身Vae解码器解码的内容与放大器模型的信息进行混合输出到后续环节

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-f46b66202fa207b5fdff6eafe5875ca3_b.jpg)

## **2.3 调节器**

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/20240220171959.png)

调节器的功能在上面举例加载器的时候提到了一部分。这里以一部分基础版本的调节器举例，整体的功能都是作为一个并联的中转器。将前面的内容整合搭配输入到后续的环节。

这里主要介绍两个内容。一个是condintion系列的调节器节点。另一个是基于SDXL的调节器。

首先说到condintion主要是将图片的潜空间信息进行整合调节的节点。位置都是链接在clip编码器到KSampler采样器之间。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/20240220172117.png)

以上方这个工作流举例，左边的都是加载器，将底模型，画面尺寸信息输入到采样器之中。

中间加入的流程就是三个condintion调节器。其中两个是set area调节器。一个是combine调节器。它们的功能分别是将信息控制在不同的尺寸之中。同时组合在同一个图片之下一起出来。

详细拆解可以得出，画面之中首先创建一个宽画幅画布，然后将内容拆解成两个独立的画面内容

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-a58c560c14f27b6120756f7467ece05f_b.jpg)

每一个单独的部分尺寸划分使用set area调节器进行输出。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-5a26a40fa29b5535614bcc6c57536641_b.jpg)

然后使用combine节点来将这两个图片整合在一起。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-63d1c0750458476362c5c96fb6214feb_b.jpg)

顺便提一下就是如果是需要将背景整合成为一张的话可以之间从ckpt节点上链接一个clip正向词作为一个额外的并联装置来和之前的combine进行组合，再通过一个新的combine输出。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/20240220172238.png)


然后这里介绍下基于SDXL的调节器，如上图这是一个基于sdxl base模型的文生图工作流。

和基础1.5的整体都比较接近。主要的区别就是中间的clip编码器

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-c5687e0433fcc557e41e23e5d3f022e5_b.jpg)

这里是将文字解码单独拆成了两个部分，专门的编码器然后通过专门的primtive节点单独输入信息。

相比的优势在于可以同时通过一套primtive节点同时链接多个编码器。这也是SDxl的思路流程

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-b58a4a69023958c691ca38ca10a83086_b.jpg)

例如上面这个，就是基于基础的base模型的工作流组合了一个refine模型（紫色），整个的流程思路可以拆解为

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-44cc54c7530a561e219e4511fa2c6e46_b.jpg)

base底模输出内容到clip编码器，同时文字信息也并联输入，编码器整个之后输入到采样器，其中的步数单独提出节点进行统一调节。输出成为第一个预览。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-2d4650165c972613c6cccf11917d0366_b.jpg)

然后第一个预览的潜空间图像信息同步链接到一个新的采样器作为图像信息输入，同时还有一套refine的底模来使用同一套词，同一个步数来对这张图进行优化调整完善。

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-40e9a7210fd64aab1b5f9f3959f62419_b.jpg)

![](https://qhdtc.oss-cn-chengdu.aliyuncs.com/obsidian/v2-c781312e23be53b6c62db93e99d0cba5_b.jpg)

然后是潜空间和图像控制的相关的节点。这两种的功能形式类似，主要的区别在于他们针对调整内容的处理阶段。一个是在信息还处于潜空间之中的处理。另一个图像放大是在图像已经通过解码器进行输出之后的调整。

这里用一个之前文章的案例举例

这部分主要的区别在于AI的图像生成在降噪之前的信息储存是一个叫潜在空间的部分，Hirex.fix的优势在于它放大的时候是在转成图片的过程之中通过潜在高分辨率进行放大，对于细节的指定会比单纯的生成后放大差异明显。
