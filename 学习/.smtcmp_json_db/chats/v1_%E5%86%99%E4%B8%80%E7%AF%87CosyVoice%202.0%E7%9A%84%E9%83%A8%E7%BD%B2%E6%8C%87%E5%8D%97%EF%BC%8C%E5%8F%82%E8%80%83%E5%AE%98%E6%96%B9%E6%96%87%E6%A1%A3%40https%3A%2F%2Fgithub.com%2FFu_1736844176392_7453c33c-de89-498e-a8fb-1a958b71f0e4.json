{
  "id": "7453c33c-de89-498e-a8fb-1a958b71f0e4",
  "title": "å†™ä¸€ç¯‡CosyVoice 2.0çš„éƒ¨ç½²æŒ‡å—ï¼Œå‚è€ƒå®˜æ–¹æ–‡æ¡£@https://github.com/Fu",
  "messages": [
    {
      "role": "user",
      "content": {
        "root": {
          "children": [
            {
              "children": [
                {
                  "detail": 0,
                  "format": 0,
                  "mode": "normal",
                  "style": "",
                  "text": "å†™ä¸€ç¯‡CosyVoice 2.0çš„éƒ¨ç½²æŒ‡å—ï¼Œå‚è€ƒå®˜æ–¹æ–‡æ¡£",
                  "type": "text",
                  "version": 1
                },
                {
                  "detail": 1,
                  "format": 0,
                  "mode": "token",
                  "style": "",
                  "text": "@https://github.com/FunAudioLLM/CosyVoice",
                  "type": "mention",
                  "version": 1,
                  "mentionName": "https://github.com/FunAudioLLM/CosyVoice",
                  "mentionable": {
                    "type": "url",
                    "url": "https://github.com/FunAudioLLM/CosyVoice"
                  }
                },
                {
                  "detail": 0,
                  "format": 0,
                  "mode": "normal",
                  "style": "",
                  "text": " ",
                  "type": "text",
                  "version": 1
                }
              ],
              "direction": "ltr",
              "format": "",
              "indent": 0,
              "type": "paragraph",
              "version": 1,
              "textFormat": 0,
              "textStyle": ""
            }
          ],
          "direction": "ltr",
          "format": "",
          "indent": 0,
          "type": "root",
          "version": 1
        }
      },
      "promptContent": [
        {
          "type": "text",
          "text": "## Potentially Relevant Websearch Results\n```\nWebsite URL: https://github.com/FunAudioLLM/CosyVoice\nWebsite Content:\n                                                            \n\n[Skip to content](#start-of-content)  \n\n## Navigation Menu\n\nToggle navigation\n\n[](/)\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FFunAudioLLM%2FCosyVoice)\n\n- Product\n    \n    - [\n        \n        GitHub Copilot\n        \n        Write better code with AI\n        \n        ](https://github.com/features/copilot)\n    - [\n        \n        Security\n        \n        Find and fix vulnerabilities\n        \n        ](https://github.com/features/security)\n    - [\n        \n        Actions\n        \n        Automate any workflow\n        \n        ](https://github.com/features/actions)\n    - [\n        \n        Codespaces\n        \n        Instant dev environments\n        \n        ](https://github.com/features/codespaces)\n    - [\n        \n        Issues\n        \n        Plan and track work\n        \n        ](https://github.com/features/issues)\n    - [\n        \n        Code Review\n        \n        Manage code changes\n        \n        ](https://github.com/features/code-review)\n    - [\n        \n        Discussions\n        \n        Collaborate outside of code\n        \n        ](https://github.com/features/discussions)\n    - [\n        \n        Code Search\n        \n        Find more, search less\n        \n        ](https://github.com/features/code-search)\n    \n    Explore\n    \n    - [All features](https://github.com/features)\n    - [Documentation](https://docs.github.com)\n    - [GitHub Skills](https://skills.github.com)\n    - [Blog](https://github.blog)\n    \n- Solutions\n    \n    By company size\n    \n    - [Enterprises](https://github.com/enterprise)\n    - [Small and medium teams](https://github.com/team)\n    - [Startups](https://github.com/enterprise/startups)\n    \n    By use case\n    \n    - [DevSecOps](/solutions/use-case/devsecops)\n    - [DevOps](/solutions/use-case/devops)\n    - [CI/CD](/solutions/use-case/ci-cd)\n    - [View all use cases](/solutions/use-case)\n    \n    By industry\n    \n    - [Healthcare](/solutions/industry/healthcare)\n    - [Financial services](/solutions/industry/financial-services)\n    - [Manufacturing](/solutions/industry/manufacturing)\n    - [Government](/solutions/industry/government)\n    - [View all industries](/solutions/industry)\n    \n    [View all solutions](/solutions)\n    \n- Resources\n    \n    Topics\n    \n    - [AI](/resources/articles/ai)\n    - [DevOps](/resources/articles/devops)\n    - [Security](/resources/articles/security)\n    - [Software Development](/resources/articles/software-development)\n    - [View all](/resources/articles)\n    \n    Explore\n    \n    - [Learning Pathways](https://resources.github.com/learn/pathways)\n    - [White papers, Ebooks, Webinars](https://resources.github.com)\n    - [Customer Stories](https://github.com/customer-stories)\n    - [Partners](https://partner.github.com)\n    - [Executive Insights](https://github.com/solutions/executive-insights)\n    \n- Open Source\n    \n    - [\n        \n        GitHub Sponsors\n        \n        Fund open source developers\n        \n        ](/sponsors)\n    \n    - [\n        \n        The ReadME Project\n        \n        GitHub community articles\n        \n        ](https://github.com/readme)\n    \n    Repositories\n    \n    - [Topics](https://github.com/topics)\n    - [Trending](https://github.com/trending)\n    - [Collections](https://github.com/collections)\n    \n- Enterprise\n    \n    - [\n        \n        Enterprise platform\n        \n        AI-powered developer platform\n        \n        ](/enterprise)\n    \n    Available add-ons\n    \n    - [\n        \n        Advanced Security\n        \n        Enterprise-grade security features\n        \n        ](https://github.com/enterprise/advanced-security)\n    - [\n        \n        GitHub Copilot\n        \n        Enterprise-grade AI features\n        \n        ](/features/copilot#enterprise)\n    - [\n        \n        Premium Support\n        \n        Enterprise-grade 24/7 support\n        \n        ](/premium-support)\n    \n- [Pricing](https://github.com/pricing)\n\nSearch or jump to...\n\n# Search code, repositories, users, issues, pull requests...\n\nSearch\n\nClear\n\n[Search syntax tips](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax)\n\n# Provide feedback\n\nWe read every piece of feedback, and take your input very seriously.\n\n Include my email address so I can be contacted\n\nCancel Submit feedback\n\n# Saved searches\n\n## Use saved searches to filter your results more quickly\n\nName  \n\nQuery \n\nTo see all available qualifiers, see our [documentation](https://docs.github.com/search-github/github-code-search/understanding-github-code-search-syntax).\n\nCancel Create saved search\n\n[Sign in](/login?return_to=https%3A%2F%2Fgithub.com%2FFunAudioLLM%2FCosyVoice)\n\n[Sign up](/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F%3Cuser-name%3E%2F%3Crepo-name%3E&source=header-repo&source_repo=FunAudioLLM%2FCosyVoice) Reseting focus\n\nYou signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert\n\n[FunAudioLLM](/FunAudioLLM) / **[CosyVoice](/FunAudioLLM/CosyVoice)** Public\n\n- [Notifications](/login?return_to=%2FFunAudioLLM%2FCosyVoice) You must be signed in to change notification settings\n- [Fork 924](/login?return_to=%2FFunAudioLLM%2FCosyVoice)\n- [Star 9.5k](/login?return_to=%2FFunAudioLLM%2FCosyVoice)\n    \n\nMulti-lingual large voice generation model, providing inference, training and deployment full-stack ability.\n\n[funaudiollm.github.io/cosyvoice2](https://funaudiollm.github.io/cosyvoice2 \"https://funaudiollm.github.io/cosyvoice2\")\n\n### License\n\n[Apache-2.0 license](/FunAudioLLM/CosyVoice/blob/main/LICENSE)\n\n[9.5k stars](/FunAudioLLM/CosyVoice/stargazers) [924 forks](/FunAudioLLM/CosyVoice/forks) [Branches](/FunAudioLLM/CosyVoice/branches) [Tags](/FunAudioLLM/CosyVoice/tags) [Activity](/FunAudioLLM/CosyVoice/activity)\n\n[Star](/login?return_to=%2FFunAudioLLM%2FCosyVoice)\n\n[Notifications](/login?return_to=%2FFunAudioLLM%2FCosyVoice) You must be signed in to change notification settings\n\n- [Code](/FunAudioLLM/CosyVoice)\n- [Issues 468](/FunAudioLLM/CosyVoice/issues)\n- [Pull requests 6](/FunAudioLLM/CosyVoice/pulls)\n- [Actions](/FunAudioLLM/CosyVoice/actions)\n- [Projects 0](/FunAudioLLM/CosyVoice/projects)\n- [Security](/FunAudioLLM/CosyVoice/security)\n- [Insights](/FunAudioLLM/CosyVoice/pulse)\n\nAdditional navigation options\n\n- [Code](/FunAudioLLM/CosyVoice)\n- [Issues](/FunAudioLLM/CosyVoice/issues)\n- [Pull requests](/FunAudioLLM/CosyVoice/pulls)\n- [Actions](/FunAudioLLM/CosyVoice/actions)\n- [Projects](/FunAudioLLM/CosyVoice/projects)\n- [Security](/FunAudioLLM/CosyVoice/security)\n- [Insights](/FunAudioLLM/CosyVoice/pulse)\n\n# FunAudioLLM/CosyVoice\n\n  \n\nÂ main\n\n[Branches](/FunAudioLLM/CosyVoice/branches)[Tags](/FunAudioLLM/CosyVoice/tags)\n\n[](/FunAudioLLM/CosyVoice/branches)[](/FunAudioLLM/CosyVoice/tags)\n\nGo to file\n\nCode\n\n## Folders and files\n\n|Name|   |Name|Last commit message|Last commit date|\n|---|---|---|---|---|\n|## Latest commit<br><br>## History<br><br>[290 Commits](/FunAudioLLM/CosyVoice/commits/main/)<br><br>[](/FunAudioLLM/CosyVoice/commits/main/)|   |   |\n|[.github](/FunAudioLLM/CosyVoice/tree/main/.github \".github\")|   |[.github](/FunAudioLLM/CosyVoice/tree/main/.github \".github\")|||\n|[asset](/FunAudioLLM/CosyVoice/tree/main/asset \"asset\")|   |[asset](/FunAudioLLM/CosyVoice/tree/main/asset \"asset\")|||\n|[cosyvoice](/FunAudioLLM/CosyVoice/tree/main/cosyvoice \"cosyvoice\")|   |[cosyvoice](/FunAudioLLM/CosyVoice/tree/main/cosyvoice \"cosyvoice\")|||\n|[docker](/FunAudioLLM/CosyVoice/tree/main/docker \"docker\")|   |[docker](/FunAudioLLM/CosyVoice/tree/main/docker \"docker\")|||\n|[examples](/FunAudioLLM/CosyVoice/tree/main/examples \"examples\")|   |[examples](/FunAudioLLM/CosyVoice/tree/main/examples \"examples\")|||\n|[runtime/python](/FunAudioLLM/CosyVoice/tree/main/runtime/python \"This path skips through empty directories\")|   |[runtime/python](/FunAudioLLM/CosyVoice/tree/main/runtime/python \"This path skips through empty directories\")|||\n|[third_party](/FunAudioLLM/CosyVoice/tree/main/third_party \"third_party\")|   |[third_party](/FunAudioLLM/CosyVoice/tree/main/third_party \"third_party\")|||\n|[tools](/FunAudioLLM/CosyVoice/tree/main/tools \"tools\")|   |[tools](/FunAudioLLM/CosyVoice/tree/main/tools \"tools\")|||\n|[.gitignore](/FunAudioLLM/CosyVoice/blob/main/.gitignore \".gitignore\")|   |[.gitignore](/FunAudioLLM/CosyVoice/blob/main/.gitignore \".gitignore\")|||\n|[.gitmodules](/FunAudioLLM/CosyVoice/blob/main/.gitmodules \".gitmodules\")|   |[.gitmodules](/FunAudioLLM/CosyVoice/blob/main/.gitmodules \".gitmodules\")|||\n|[CODE_OF_CONDUCT.md](/FunAudioLLM/CosyVoice/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")|   |[CODE_OF_CONDUCT.md](/FunAudioLLM/CosyVoice/blob/main/CODE_OF_CONDUCT.md \"CODE_OF_CONDUCT.md\")|||\n|[FAQ.md](/FunAudioLLM/CosyVoice/blob/main/FAQ.md \"FAQ.md\")|   |[FAQ.md](/FunAudioLLM/CosyVoice/blob/main/FAQ.md \"FAQ.md\")|||\n|[LICENSE](/FunAudioLLM/CosyVoice/blob/main/LICENSE \"LICENSE\")|   |[LICENSE](/FunAudioLLM/CosyVoice/blob/main/LICENSE \"LICENSE\")|||\n|[README.md](/FunAudioLLM/CosyVoice/blob/main/README.md \"README.md\")|   |[README.md](/FunAudioLLM/CosyVoice/blob/main/README.md \"README.md\")|||\n|[requirements.txt](/FunAudioLLM/CosyVoice/blob/main/requirements.txt \"requirements.txt\")|   |[requirements.txt](/FunAudioLLM/CosyVoice/blob/main/requirements.txt \"requirements.txt\")|||\n|[webui.py](/FunAudioLLM/CosyVoice/blob/main/webui.py \"webui.py\")|   |[webui.py](/FunAudioLLM/CosyVoice/blob/main/webui.py \"webui.py\")|||\n|View all files|   |   |\n\n## Repository files navigation\n\n- [README](#)\n- [Code of conduct](#)\n- [Apache-2.0 license](#)\n\n[![SVG Banners](https://camo.githubusercontent.com/ccfefbc067e7c75da49f8c9c867132d6934dedd44aa1d3297ab4125770f9120a/68747470733a2f2f7376672d62616e6e6572732e76657263656c2e6170702f6170693f747970653d6f726967696e2674657874313d436f7379566f6963652546302539462541342541302674657874323d546578742d746f2d5370656563682532302546302539462539322539362532304c617267652532304c616e67756167652532304d6f64656c2677696474683d383030266865696768743d323130)](https://github.com/Akshay090/svg-banners)\n\n## ğŸ‘‰ğŸ» CosyVoice ğŸ‘ˆğŸ»\n\n[](#-cosyvoice-)\n\n**CosyVoice 2.0**: [Demos](https://funaudiollm.github.io/cosyvoice2/); [Paper](https://arxiv.org/abs/2412.10117); [Modelscope](https://www.modelscope.cn/studios/iic/CosyVoice2-0.5B); [HuggingFace](https://huggingface.co/spaces/FunAudioLLM/CosyVoice2-0.5B)\n\n**CosyVoice 1.0**: [Demos](https://fun-audio-llm.github.io); [Paper](https://funaudiollm.github.io/pdf/CosyVoice_v1.pdf); [Modelscope](https://www.modelscope.cn/studios/iic/CosyVoice-300M)\n\n## HighlightğŸ”¥\n\n[](#highlight)\n\n**CosyVoice 2.0** has been released! Compared to version 1.0, the new version offers more accurate, more stable, faster, and better speech generation capabilities.\n\n### Multilingual\n\n[](#multilingual)\n\n- **Supported Language**: Chinese, English, Japanese, Korean, Chinese dialects (Cantonese, Sichuanese, Shanghainese, Tianjinese, Wuhanese, etc.)\n- **Crosslingual & Mixlingual**ï¼šSupport zero-shot voice cloning for cross-lingual and code-switching scenarios.\n\n### Ultra-Low Latency\n\n[](#ultra-low-latency)\n\n- **Bidirectional Streaming Support**: CosyVoice 2.0 integrates offline and streaming modeling technologies.\n- **Rapid First Packet Synthesis**: Achieves latency as low as 150ms while maintaining high-quality audio output.\n\n### High Accuracy\n\n[](#high-accuracy)\n\n- **Improved Pronunciation**: Reduces pronunciation errors by 30% to 50% compared to CosyVoice 1.0.\n- **Benchmark Achievements**: Attains the lowest character error rate on the hard test set of the Seed-TTS evaluation set.\n\n### Strong Stability\n\n[](#strong-stability)\n\n- **Consistency in Timbre**: Ensures reliable voice consistency for zero-shot and cross-language speech synthesis.\n- **Cross-language Synthesis**: Marked improvements compared to version 1.0.\n\n### Natural Experience\n\n[](#natural-experience)\n\n- **Enhanced Prosody and Sound Quality**: Improved alignment of synthesized audio, raising MOS evaluation scores from 5.4 to 5.53.\n- **Emotional and Dialectal Flexibility**: Now supports more granular emotional controls and accent adjustments.\n\n## Roadmap\n\n[](#roadmap)\n\n-  2024/12\n    \n    - [x]  25hz cosyvoice 2.0 released\n-  2024/09\n    \n    - [x]  25hz cosyvoice base model\n    - [x]  25hz cosyvoice voice conversion model\n-  2024/08\n    \n    - [x]  Repetition Aware Sampling(RAS) inference for llm stability\n    - [x]  Streaming inference mode support, including kv cache and sdpa for rtf optimization\n-  2024/07\n    \n    - [x]  Flow matching training support\n    - [x]  WeTextProcessing support when ttsfrd is not available\n    - [x]  Fastapi server and client\n\n## Install\n\n[](#install)\n\n**Clone and install**\n\n- Clone the repo\n\n```shell\ngit clone --recursive https://github.com/FunAudioLLM/CosyVoice.git\n# If you failed to clone submodule due to network failures, please run following command until success\ncd CosyVoice\ngit submodule update --init --recursive\n```\n\n- Install Conda: please see [https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html)\n- Create Conda env:\n\n```shell\nconda create -n cosyvoice -y python=3.10\nconda activate cosyvoice\n# pynini is required by WeTextProcessing, use conda to install it as it can be executed on all platform.\nconda install -y -c conda-forge pynini==2.1.5\npip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com\n\n# If you encounter sox compatibility issues\n# ubuntu\nsudo apt-get install sox libsox-dev\n# centos\nsudo yum install sox sox-devel\n```\n\n**Model download**\n\nWe strongly recommend that you download our pretrained `CosyVoice2-0.5B` `CosyVoice-300M` `CosyVoice-300M-SFT` `CosyVoice-300M-Instruct` model and `CosyVoice-ttsfrd` resource.\n\n```python\n# SDKæ¨¡å‹ä¸‹è½½\nfrom modelscope import snapshot_download\nsnapshot_download('iic/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')\nsnapshot_download('iic/CosyVoice-300M', local_dir='pretrained_models/CosyVoice-300M')\nsnapshot_download('iic/CosyVoice-300M-25Hz', local_dir='pretrained_models/CosyVoice-300M-25Hz')\nsnapshot_download('iic/CosyVoice-300M-SFT', local_dir='pretrained_models/CosyVoice-300M-SFT')\nsnapshot_download('iic/CosyVoice-300M-Instruct', local_dir='pretrained_models/CosyVoice-300M-Instruct')\nsnapshot_download('iic/CosyVoice-ttsfrd', local_dir='pretrained_models/CosyVoice-ttsfrd')\n```\n\n```shell\n# gitæ¨¡å‹ä¸‹è½½ï¼Œè¯·ç¡®ä¿å·²å®‰è£…git lfs\nmkdir -p pretrained_models\ngit clone https://www.modelscope.cn/iic/CosyVoice2-0.5B.git pretrained_models/CosyVoice2-0.5B\ngit clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M\ngit clone https://www.modelscope.cn/iic/CosyVoice-300M-25Hz.git pretrained_models/CosyVoice-300M-25Hz\ngit clone https://www.modelscope.cn/iic/CosyVoice-300M-SFT.git pretrained_models/CosyVoice-300M-SFT\ngit clone https://www.modelscope.cn/iic/CosyVoice-300M-Instruct.git pretrained_models/CosyVoice-300M-Instruct\ngit clone https://www.modelscope.cn/iic/CosyVoice-ttsfrd.git pretrained_models/CosyVoice-ttsfrd\n```\n\nOptionally, you can unzip `ttsfrd` resouce and install `ttsfrd` package for better text normalization performance.\n\nNotice that this step is not necessary. If you do not install `ttsfrd` package, we will use WeTextProcessing by default.\n\n```shell\ncd pretrained_models/CosyVoice-ttsfrd/\nunzip resource.zip -d .\npip install ttsfrd_dependency-0.1-py3-none-any.whl\npip install ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl\n```\n\n**Basic Usage**\n\nWe strongly recommend using `CosyVoice2-0.5B` for better performance. Follow code below for detailed usage of each model.\n\n```python\nimport sys\nsys.path.append('third_party/Matcha-TTS')\nfrom cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2\nfrom cosyvoice.utils.file_utils import load_wav\nimport torchaudio\n```\n\n**CosyVoice2 Usage**\n\n```python\ncosyvoice = CosyVoice2('pretrained_models/CosyVoice2-0.5B', load_jit=False, load_trt=False, fp16=False)\n\n# NOTE if you want to reproduce the results on https://funaudiollm.github.io/cosyvoice2, please add text_frontend=False during inference\n# zero_shot usage\nprompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)\nfor i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):\n    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n\n# fine grained control, for supported control, check cosyvoice/tokenizer/tokenizer.py#L248\nfor i, j in enumerate(cosyvoice.inference_cross_lingual('åœ¨ä»–è®²è¿°é‚£ä¸ªè’è¯æ•…äº‹çš„è¿‡ç¨‹ä¸­ï¼Œä»–çªç„¶[laughter]åœä¸‹æ¥ï¼Œå› ä¸ºä»–è‡ªå·±ä¹Ÿè¢«é€—ç¬‘äº†[laughter]ã€‚', prompt_speech_16k, stream=False)):\n    torchaudio.save('fine_grained_control_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n\n# instruct usage\nfor i, j in enumerate(cosyvoice.inference_instruct2('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'ç”¨å››å·è¯è¯´è¿™å¥è¯', prompt_speech_16k, stream=False)):\n    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n```\n\n**CosyVoice Usage**\n\n```python\ncosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-SFT', load_jit=False, load_trt=False, fp16=False)\n# sft usage\nprint(cosyvoice.list_available_spks())\n# change stream=True for chunk stream inference\nfor i, j in enumerate(cosyvoice.inference_sft('ä½ å¥½ï¼Œæˆ‘æ˜¯é€šä¹‰ç”Ÿæˆå¼è¯­éŸ³å¤§æ¨¡å‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ', 'ä¸­æ–‡å¥³', stream=False)):\n    torchaudio.save('sft_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n\ncosyvoice = CosyVoice('pretrained_models/CosyVoice-300M') # or change to pretrained_models/CosyVoice-300M-25Hz for 25Hz inference\n# zero_shot usage, <|zh|><|en|><|jp|><|yue|><|ko|> for Chinese/English/Japanese/Cantonese/Korean\nprompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)\nfor i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):\n    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n# cross_lingual usage\nprompt_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)\nfor i, j in enumerate(cosyvoice.inference_cross_lingual('<|en|>And then later on, fully acquiring that company. So keeping management in line, interest in line with the asset that\\'s coming into the family is a reason why sometimes we don\\'t buy the whole thing.', prompt_speech_16k, stream=False)):\n    torchaudio.save('cross_lingual_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n# vc usage\nprompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)\nsource_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)\nfor i, j in enumerate(cosyvoice.inference_vc(source_speech_16k, prompt_speech_16k, stream=False)):\n    torchaudio.save('vc_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n\ncosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-Instruct')\n# instruct usage, support <laughter></laughter><strong></strong>[laughter][breath]\nfor i, j in enumerate(cosyvoice.inference_instruct('åœ¨é¢å¯¹æŒ‘æˆ˜æ—¶ï¼Œä»–å±•ç°äº†éå‡¡çš„<strong>å‹‡æ°”</strong>ä¸<strong>æ™ºæ…§</strong>ã€‚', 'ä¸­æ–‡ç”·', 'Theo \\'Crimson\\', is a fiery, passionate rebel leader. Fights with fervor for justice, but struggles with impulsiveness.', stream=False)):\n    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n```\n\n**Start web demo**\n\nYou can use our web demo page to get familiar with CosyVoice quickly.\n\nPlease see the demo website for details.\n\n```python\n# change iic/CosyVoice-300M-SFT for sft inference, or iic/CosyVoice-300M-Instruct for instruct inference\npython3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice-300M\n```\n\n**Advanced Usage**\n\nFor advanced user, we have provided train and inference scripts in `examples/libritts/cosyvoice/run.sh`.\n\n**Build for deployment**\n\nOptionally, if you want service deployment, you can run following steps.\n\n```shell\ncd runtime/python\ndocker build -t cosyvoice:v1.0 .\n# change iic/CosyVoice-300M to iic/CosyVoice-300M-Instruct if you want to use instruct inference\n# for grpc usage\ndocker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c \"cd /opt/CosyVoice/CosyVoice/runtime/python/grpc && python3 server.py --port 50000 --max_conc 4 --model_dir iic/CosyVoice-300M && sleep infinity\"\ncd grpc && python3 client.py --port 50000 --mode <sft|zero_shot|cross_lingual|instruct>\n# for fastapi usage\ndocker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c \"cd /opt/CosyVoice/CosyVoice/runtime/python/fastapi && python3 server.py --port 50000 --model_dir iic/CosyVoice-300M && sleep infinity\"\ncd fastapi && python3 client.py --port 50000 --mode <sft|zero_shot|cross_lingual|instruct>\n```\n\n## Discussion & Communication\n\n[](#discussion--communication)\n\nYou can directly discuss on [Github Issues](https://github.com/FunAudioLLM/CosyVoice/issues).\n\nYou can also scan the QR code to join our official Dingding chat group.\n\n[![](/FunAudioLLM/CosyVoice/raw/main/asset/dingding.png)](/FunAudioLLM/CosyVoice/blob/main/asset/dingding.png)\n\n## Acknowledge\n\n[](#acknowledge)\n\n1. We borrowed a lot of code from [FunASR](https://github.com/modelscope/FunASR).\n2. We borrowed a lot of code from [FunCodec](https://github.com/modelscope/FunCodec).\n3. We borrowed a lot of code from [Matcha-TTS](https://github.com/shivammehta25/Matcha-TTS).\n4. We borrowed a lot of code from [AcademiCodec](https://github.com/yangdongchao/AcademiCodec).\n5. We borrowed a lot of code from [WeNet](https://github.com/wenet-e2e/wenet).\n\n## Disclaimer\n\n[](#disclaimer)\n\nThe content provided above is for academic purposes only and is intended to demonstrate technical capabilities. Some examples are sourced from the internet. If any content infringes on your rights, please contact us to request its removal.\n\n## About\n\nMulti-lingual large voice generation model, providing inference, training and deployment full-stack ability.\n\n[funaudiollm.github.io/cosyvoice2](https://funaudiollm.github.io/cosyvoice2 \"https://funaudiollm.github.io/cosyvoice2\")\n\n### Topics\n\n[python](/topics/python \"Topic: python\") [text-to-speech](/topics/text-to-speech \"Topic: text-to-speech\") [japanese](/topics/japanese \"Topic: japanese\") [chatbot](/topics/chatbot \"Topic: chatbot\") [multi-lingual](/topics/multi-lingual \"Topic: multi-lingual\") [tts](/topics/tts \"Topic: tts\") [english](/topics/english \"Topic: english\") [chinese](/topics/chinese \"Topic: chinese\") [korean](/topics/korean \"Topic: korean\") [cantonese](/topics/cantonese \"Topic: cantonese\") [natural-language-generation](/topics/natural-language-generation \"Topic: natural-language-generation\") [cross-lingual](/topics/cross-lingual \"Topic: cross-lingual\") [fine-grained](/topics/fine-grained \"Topic: fine-grained\") [fine-tuning](/topics/fine-tuning \"Topic: fine-tuning\") [voice-cloning](/topics/voice-cloning \"Topic: voice-cloning\") [audio-generation](/topics/audio-generation \"Topic: audio-generation\") [chatgpt](/topics/chatgpt \"Topic: chatgpt\") [gpt-4o](/topics/gpt-4o \"Topic: gpt-4o\") [cosyvoice](/topics/cosyvoice \"Topic: cosyvoice\")\n\n### Resources\n\n[Readme](#readme-ov-file)\n\n### License\n\n[Apache-2.0 license](#Apache-2.0-1-ov-file)\n\n### Code of conduct\n\n[Code of conduct](#coc-ov-file)\n\n[Activity](/FunAudioLLM/CosyVoice/activity)\n\n[Custom properties](/FunAudioLLM/CosyVoice/custom-properties)\n\n### Stars\n\n[**9.5k** stars](/FunAudioLLM/CosyVoice/stargazers)\n\n### Watchers\n\n[**86** watching](/FunAudioLLM/CosyVoice/watchers)\n\n### Forks\n\n[**924** forks](/FunAudioLLM/CosyVoice/forks)\n\n[Report repository](/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2FFunAudioLLM%2FCosyVoice&report=FunAudioLLM+%28user%29)\n\n## [Packages 0](/orgs/FunAudioLLM/packages?repo_name=CosyVoice)\n\nNo packages published  \n\n## [Contributors 24](/FunAudioLLM/CosyVoice/graphs/contributors)\n\n- [![@aluminumbox](https://avatars.githubusercontent.com/u/31685265?s=64&v=4)](https://github.com/aluminumbox)\n- [![@ZhihaoDU](https://avatars.githubusercontent.com/u/28995683?s=64&v=4)](https://github.com/ZhihaoDU)\n- [![@v3ucn](https://avatars.githubusercontent.com/u/1288038?s=64&v=4)](https://github.com/v3ucn)\n- [![@iflamed](https://avatars.githubusercontent.com/u/1819687?s=64&v=4)](https://github.com/iflamed)\n- [![@tramphero](https://avatars.githubusercontent.com/u/30189297?s=64&v=4)](https://github.com/tramphero)\n- [![@0xCAFEBABE0](https://avatars.githubusercontent.com/u/14041744?s=64&v=4)](https://github.com/0xCAFEBABE0)\n- [![@hexisyztem](https://avatars.githubusercontent.com/u/25223224?s=64&v=4)](https://github.com/hexisyztem)\n- [![@passerbya](https://avatars.githubusercontent.com/u/758077?s=64&v=4)](https://github.com/passerbya)\n- [![@zhuzizyf](https://avatars.githubusercontent.com/u/42790740?s=64&v=4)](https://github.com/zhuzizyf)\n- [![@MiXaiLL76](https://avatars.githubusercontent.com/u/31501945?s=64&v=4)](https://github.com/MiXaiLL76)\n- [![@boji123](https://avatars.githubusercontent.com/u/13692002?s=64&v=4)](https://github.com/boji123)\n- [![@tyanz](https://avatars.githubusercontent.com/u/18299962?s=64&v=4)](https://github.com/tyanz)\n- [![@garywill](https://avatars.githubusercontent.com/u/32130780?s=64&v=4)](https://github.com/garywill)\n- [![@Vinkle-hzt](https://avatars.githubusercontent.com/u/55839372?s=64&v=4)](https://github.com/Vinkle-hzt)\n\n[+ 10 contributors](/FunAudioLLM/CosyVoice/graphs/contributors)\n\n## Languages\n\n- [Python 99.0%](/FunAudioLLM/CosyVoice/search?l=python)\n- Other 1.0%\n\n## Footer\n\n[](https://github.com \"GitHub\")Â© 2025 GitHub,Â Inc.\n\n### Footer navigation\n\n- [Terms](https://docs.github.com/site-policy/github-terms/github-terms-of-service)\n- [Privacy](https://docs.github.com/site-policy/privacy-policies/github-privacy-statement)\n- [Security](https://github.com/security)\n- [Status](https://www.githubstatus.com/)\n- [Docs](https://docs.github.com/)\n- [Contact](https://support.github.com?tags=dotcom-footer)\n- Manage cookies\n- Do not share my personal information\n\nYou canâ€™t perform that action at this time.\n```\n\n\nå†™ä¸€ç¯‡CosyVoice 2.0çš„éƒ¨ç½²æŒ‡å—ï¼Œå‚è€ƒå®˜æ–¹æ–‡æ¡£@https://github.com/FunAudioLLM/CosyVoice \n\n"
        }
      ],
      "id": "b70b1d22-3a10-4819-8b3b-757115abf5b4",
      "mentionables": [
        {
          "type": "current-file",
          "file": "5Â·AI/5Â·è¯­éŸ³/CosyVoice 2.0.md"
        },
        {
          "type": "url",
          "url": "https://github.com/FunAudioLLM/CosyVoice"
        }
      ]
    },
    {
      "role": "assistant",
      "content": "å¥½çš„ï¼Œè¿™æ˜¯åŸºäºå®˜æ–¹æ–‡æ¡£çš„ CosyVoice 2.0 éƒ¨ç½²æŒ‡å—ï¼š\n\n<smtcmp_block filename=\"5Â·AI/5Â·è¯­éŸ³/CosyVoice 2.0.md\" language=\"markdown\">\n# CosyVoice 2.0 éƒ¨ç½²æŒ‡å—\n\n## ç®€ä»‹\n[CosyVoice 2.0](https://github.com/FunAudioLLM/CosyVoice) æ˜¯ä¸€ä¸ªå¤šè¯­è¨€å¤§å‹è¯­éŸ³ç”Ÿæˆæ¨¡å‹ï¼Œæä¾›æ¨ç†ã€è®­ç»ƒå’Œéƒ¨ç½²çš„å…¨æ ˆèƒ½åŠ›ã€‚\n\n## ç¯å¢ƒå‡†å¤‡\n\n### 1. å…‹éš†ä»“åº“\n```shell\ngit clone --recursive https://github.com/FunAudioLLM/CosyVoice.git\ncd CosyVoice\ngit submodule update --init --recursive\n```\nå¦‚æœå› ä¸ºç½‘ç»œé—®é¢˜å¯¼è‡´å­æ¨¡å—å…‹éš†å¤±è´¥ï¼Œè¯·é‡å¤è¿è¡Œ `git submodule update --init --recursive` ç›´åˆ°æˆåŠŸã€‚\n\n### 2. å®‰è£… Conda\nè¯·å‚è€ƒ [https://docs.conda.io/en/latest/miniconda.html](https://docs.conda.io/en/latest/miniconda.html) å®‰è£… Condaã€‚\n\n### 3. åˆ›å»ºå¹¶æ¿€æ´» Conda ç¯å¢ƒ\n```shell\nconda create -n cosyvoice -y python=3.10\nconda activate cosyvoice\n```\n\n### 4. å®‰è£…ä¾èµ–\n```shell\nconda install -y -c conda-forge pynini==2.1.5\npip install -r requirements.txt -i https://mirrors.aliyun.com/pypi/simple/ --trusted-host=mirrors.aliyun.com\n```\n\n### 5. (å¯é€‰)è§£å†³ sox å…¼å®¹æ€§é—®é¢˜\n```shell\n# ubuntu\nsudo apt-get install sox libsox-dev\n# centos\nsudo yum install sox sox-devel\n```\n\n## æ¨¡å‹ä¸‹è½½\n\næˆ‘ä»¬å¼ºçƒˆå»ºè®®ä¸‹è½½é¢„è®­ç»ƒçš„ `CosyVoice2-0.5B`, `CosyVoice-300M`, `CosyVoice-300M-SFT`, `CosyVoice-300M-Instruct` æ¨¡å‹ä»¥åŠ `CosyVoice-ttsfrd` èµ„æºã€‚\n\n### 1. ä½¿ç”¨ SDK ä¸‹è½½ (æ¨è)\n```python\nfrom modelscope import snapshot_download\nsnapshot_download('iic/CosyVoice2-0.5B', local_dir='pretrained_models/CosyVoice2-0.5B')\nsnapshot_download('iic/CosyVoice-300M', local_dir='pretrained_models/CosyVoice-300M')\nsnapshot_download('iic/CosyVoice-300M-25Hz', local_dir='pretrained_models/CosyVoice-300M-25Hz')\nsnapshot_download('iic/CosyVoice-300M-SFT', local_dir='pretrained_models/CosyVoice-300M-SFT')\nsnapshot_download('iic/CosyVoice-300M-Instruct', local_dir='pretrained_models/CosyVoice-300M-Instruct')\nsnapshot_download('iic/CosyVoice-ttsfrd', local_dir='pretrained_models/CosyVoice-ttsfrd')\n```\n\n### 2. ä½¿ç”¨ Git ä¸‹è½½\n```shell\nmkdir -p pretrained_models\ngit clone https://www.modelscope.cn/iic/CosyVoice2-0.5B.git pretrained_models/CosyVoice2-0.5B\ngit clone https://www.modelscope.cn/iic/CosyVoice-300M.git pretrained_models/CosyVoice-300M\ngit clone https://www.modelscope.cn/iic/CosyVoice-300M-25Hz.git pretrained_models/CosyVoice-300M-25Hz\ngit clone https://www.modelscope.cn/iic/CosyVoice-300M-SFT.git pretrained_models/CosyVoice-300M-SFT\ngit clone https://www.modelscope.cn/iic/CosyVoice-300M-Instruct.git pretrained_models/CosyVoice-300M-Instruct\ngit clone https://www.modelscope.cn/iic/CosyVoice-ttsfrd.git pretrained_models/CosyVoice-ttsfrd\n```\nè¯·ç¡®ä¿å·²å®‰è£… `git lfs`ã€‚\n\n### 3. (å¯é€‰)è§£å‹å¹¶å®‰è£… ttsfrd\nå¦‚æœéœ€è¦æ›´å¥½çš„æ–‡æœ¬å½’ä¸€åŒ–æ€§èƒ½ï¼Œå¯ä»¥è§£å‹ `ttsfrd` èµ„æºå¹¶å®‰è£… `ttsfrd` åŒ…ã€‚ æ­¤æ­¥éª¤ä¸æ˜¯å¿…é¡»çš„ï¼Œå¦‚æœæœªå®‰è£… `ttsfrd` åŒ…ï¼Œé»˜è®¤å°†ä½¿ç”¨ WeTextProcessingã€‚\n```shell\ncd pretrained_models/CosyVoice-ttsfrd/\nunzip resource.zip -d .\npip install ttsfrd_dependency-0.1-py3-none-any.whl\npip install ttsfrd-0.4.2-cp310-cp310-linux_x86_64.whl\n```\n\n## åŸºæœ¬ç”¨æ³•\n\nä»¥ä¸‹ä»£ç å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ `CosyVoice2-0.5B` å’Œ `CosyVoice` æ¨¡å‹ã€‚\n```python\nimport sys\nsys.path.append('third_party/Matcha-TTS')\nfrom cosyvoice.cli.cosyvoice import CosyVoice, CosyVoice2\nfrom cosyvoice.utils.file_utils import load_wav\nimport torchaudio\n```\n\n### CosyVoice2 ç”¨æ³•\n```python\ncosyvoice = CosyVoice2('pretrained_models/CosyVoice2-0.5B', load_jit=False, load_trt=False, fp16=False)\n\n# é›¶æ ·æœ¬æ¨ç†\nprompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)\nfor i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):\n    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n\n# ç»†ç²’åº¦æ§åˆ¶\nfor i, j in enumerate(cosyvoice.inference_cross_lingual('åœ¨ä»–è®²è¿°é‚£ä¸ªè’è¯æ•…äº‹çš„è¿‡ç¨‹ä¸­ï¼Œä»–çªç„¶[laughter]åœä¸‹æ¥ï¼Œå› ä¸ºä»–è‡ªå·±ä¹Ÿè¢«é€—ç¬‘äº†[laughter]ã€‚', prompt_speech_16k, stream=False)):\n    torchaudio.save('fine_grained_control_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n\n# æŒ‡ä»¤æ¨ç†\nfor i, j in enumerate(cosyvoice.inference_instruct2('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'ç”¨å››å·è¯è¯´è¿™å¥è¯', prompt_speech_16k, stream=False)):\n    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n```\n\n### CosyVoice ç”¨æ³•\n```python\ncosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-SFT', load_jit=False, load_trt=False, fp16=False)\n# sft æ¨ç†\nprint(cosyvoice.list_available_spks())\nfor i, j in enumerate(cosyvoice.inference_sft('ä½ å¥½ï¼Œæˆ‘æ˜¯é€šä¹‰ç”Ÿæˆå¼è¯­éŸ³å¤§æ¨¡å‹ï¼Œè¯·é—®æœ‰ä»€ä¹ˆå¯ä»¥å¸®æ‚¨çš„å—ï¼Ÿ', 'ä¸­æ–‡å¥³', stream=False)):\n    torchaudio.save('sft_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n\ncosyvoice = CosyVoice('pretrained_models/CosyVoice-300M') # or change to pretrained_models/CosyVoice-300M-25Hz for 25Hz inference\n# é›¶æ ·æœ¬æ¨ç†\nprompt_speech_16k = load_wav('./asset/zero_shot_prompt.wav', 16000)\nfor i, j in enumerate(cosyvoice.inference_zero_shot('æ”¶åˆ°å¥½å‹ä»è¿œæ–¹å¯„æ¥çš„ç”Ÿæ—¥ç¤¼ç‰©ï¼Œé‚£ä»½æ„å¤–çš„æƒŠå–œä¸æ·±æ·±çš„ç¥ç¦è®©æˆ‘å¿ƒä¸­å……æ»¡äº†ç”œèœœçš„å¿«ä¹ï¼Œç¬‘å®¹å¦‚èŠ±å„¿èˆ¬ç»½æ”¾ã€‚', 'å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚', prompt_speech_16k, stream=False)):\n    torchaudio.save('zero_shot_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n# è·¨è¯­è¨€æ¨ç†\nprompt_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)\nfor i, j in enumerate(cosyvoice.inference_cross_lingual('<|en|>And then later on, fully acquiring that company. So keeping management in line, interest in line with the asset that\\'s coming into the family is a reason why sometimes we don\\'t buy the whole thing.', prompt_speech_16k, stream=False)):\n    torchaudio.save('cross_lingual_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n# å˜å£°æ¨ç†\nsource_speech_16k = load_wav('./asset/cross_lingual_prompt.wav', 16000)\nfor i, j in enumerate(cosyvoice.inference_vc(source_speech_16k, prompt_speech_16k, stream=False)):\n    torchaudio.save('vc_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n\ncosyvoice = CosyVoice('pretrained_models/CosyVoice-300M-Instruct')\n# æŒ‡ä»¤æ¨ç†\nfor i, j in enumerate(cosyvoice.inference_instruct('åœ¨é¢å¯¹æŒ‘æˆ˜æ—¶ï¼Œä»–å±•ç°äº†éå‡¡çš„<strong>å‹‡æ°”</strong>ä¸<strong>æ™ºæ…§</strong>ã€‚', 'ä¸­æ–‡ç”·', 'Theo \\'Crimson\\', is a fiery, passionate rebel leader. Fights with fervor for justice, but struggles with impulsiveness.', stream=False)):\n    torchaudio.save('instruct_{}.wav'.format(i), j['tts_speech'], cosyvoice.sample_rate)\n```\n\n## å¯åŠ¨ Web Demo\n\næ‚¨å¯ä»¥ä½¿ç”¨æˆ‘ä»¬çš„ Web Demo é¡µé¢å¿«é€Ÿç†Ÿæ‚‰ CosyVoiceã€‚\n```shell\n# ä¿®æ”¹æ¨¡å‹è·¯å¾„\npython3 webui.py --port 50000 --model_dir pretrained_models/CosyVoice-300M\n```\n\n## é«˜çº§ç”¨æ³•\n\nå¯¹äºé«˜çº§ç”¨æˆ·ï¼Œæˆ‘ä»¬æä¾›äº† `examples/libritts/cosyvoice/run.sh` ä¸­çš„è®­ç»ƒå’Œæ¨ç†è„šæœ¬ã€‚\n\n## æœåŠ¡éƒ¨ç½²\n\n### 1. æ„å»º Docker é•œåƒ\n```shell\ncd runtime/python\ndocker build -t cosyvoice:v1.0 .\n```\n### 2. å¯åŠ¨ Docker å®¹å™¨ (gRPC)\n```shell\ndocker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c \"cd /opt/CosyVoice/CosyVoice/runtime/python/grpc && python3 server.py --port 50000 --max_conc 4 --model_dir iic/CosyVoice-300M && sleep infinity\"\ncd grpc && python3 client.py --port 50000 --mode <sft|zero_shot|cross_lingual|instruct>\n```\n### 3. å¯åŠ¨ Docker å®¹å™¨ (FastAPI)\n```shell\ndocker run -d --runtime=nvidia -p 50000:50000 cosyvoice:v1.0 /bin/bash -c \"cd /opt/CosyVoice/CosyVoice/runtime/python/fastapi && python3 server.py --port 50000 --model_dir iic/CosyVoice-300M && sleep infinity\"\ncd fastapi && python3 client.py --port 50000 --mode <sft|zero_shot|cross_lingual|instruct>\n```\n\n**æ³¨æ„:**\n*   è¯·å°† `iic/CosyVoice-300M` æ›¿æ¢ä¸ºæ‚¨å®é™…ä½¿ç”¨çš„æ¨¡å‹è·¯å¾„ã€‚\n*   æ ¹æ®éœ€è¦é€‰æ‹© `sft`, `zero_shot`, `cross_lingual`, æˆ– `instruct` æ¨¡å¼ã€‚\n\n## è®¨è®ºä¸äº¤æµ\n*   [Github Issues](https://github.com/FunAudioLLM/CosyVoice/issues)\n*   é’‰é’‰ç¾¤ (æ‰«æå®˜æ–¹æ–‡æ¡£ä¸­çš„äºŒç»´ç )\n</smtcmp_block>\næ­¤æ–‡æ¡£æä¾›äº† CosyVoice 2.0 çš„éƒ¨ç½²æ­¥éª¤ï¼ŒåŒ…æ‹¬ç¯å¢ƒå‡†å¤‡ã€æ¨¡å‹ä¸‹è½½ã€åŸºæœ¬ç”¨æ³•ã€Web Demo å¯åŠ¨å’ŒæœåŠ¡éƒ¨ç½²ï¼Œæ‚¨å¯ä»¥æ ¹æ®æ­¤æ–‡æ¡£è¿›è¡Œéƒ¨ç½²ã€‚\n",
      "id": "605e586f-8693-48ef-a3aa-30cff2f2dcc6",
      "metadata": {
        "usage": {
          "prompt_tokens": 9584,
          "completion_tokens": 2911,
          "total_tokens": 12495
        },
        "model": {
          "provider": "gemini",
          "model": "gemini-2.0-flash-exp"
        }
      }
    }
  ],
  "createdAt": 1736844152577,
  "updatedAt": 1736844176392,
  "schemaVersion": 1
}